{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kWw0BKj6eGE"
   },
   "source": [
    "In this lab, we are going to build a seq2seq model for translating text from English to Catalan, and will eventually visualize the attention patterns discovered by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHtee5wrHchx"
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import unicodedata\n",
    "from io import open\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MXK4fuBec6o"
   },
   "source": [
    "To ensure reproducibility of the experiments, we can set the seed to a fixed number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZyyZByjHchy"
   },
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "_ = torch.manual_seed(seed)\n",
    "_ = torch.cuda.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I68eqRSDHchz"
   },
   "outputs": [],
   "source": [
    "def plot_attention(attention, xtitle=\"Keys\", ytitle=\"Queries\"):\n",
    "    \"\"\" Plots the attention map.\"\"\"\n",
    "\n",
    "    sns.set(rc={'figure.figsize':(12, 8)})\n",
    "    ax = sns.heatmap(\n",
    "        attention.detach().cpu(),\n",
    "        linewidth=0.5,\n",
    "        cmap=\"Blues\",\n",
    "        square=True)\n",
    "\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "    ax.set_xlabel(xtitle)\n",
    "    ax.set_ylabel(ytitle)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0udAmjRsHch7"
   },
   "outputs": [],
   "source": [
    "class AdditiveAttention(nn.Module):\n",
    "    \"\"\"\n",
    "     Implements the additive attention as proposed in \"Neural Machine Translation by Jointly Learning to Align and Translate\".\n",
    "     Args:\n",
    "         q_dim (int): dimesion of the queries\n",
    "         k_dim (int): dimesion of the keys\n",
    "         attn_dim (int): dimension of intermediate vectors\n",
    "\n",
    "     Inputs: query, key, value\n",
    "        query (torch.FloatTensor):  Query Tensor   (... x T_q x d_q)\n",
    "        key (torch.FloatTensor):  Key Tensor     (... x T_k x d_k)\n",
    "        value (torch.FloatTensor):  Value Tensor   (... x T_v x d_v)\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Result of the Attention Mechanism  (... x T_q x d_v)\n",
    "        torch.FloatTensor: Attention map       (... x T_q x T_k)\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, q_dim: int, k_dim: int, attn_dim: int) -> None:\n",
    "        super(AdditiveAttention, self).__init__()\n",
    "\n",
    "        # TODO: Create projections of queries and keys\n",
    "        self.proj_q = nn.Linear(q_dim, attn_dim, bias=False)\n",
    "        self.proj_k = nn.Linear(k_dim, attn_dim, bias=False)\n",
    "\n",
    "        self.bias = nn.Parameter(torch.rand(attn_dim).uniform_(-0.1, 0.1))\n",
    "        self.w = nn.Linear(attn_dim, 1)\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        q_ = self.proj_q(query) # (... x T_q x q_dim) -> (... x T_q x attn_dim)\n",
    "        k_ = self.proj_k(key)   # (... x T_k x k_dim) -> (... x T_k x attn_dim)\n",
    "\n",
    "        # Prepare for Broadcasting Semantics\n",
    "        q_ = q_.unsqueeze(-2)   # (... x T_q x attn_dim) -> (... x T_q x  1  x attn_dim)\n",
    "        k_ = k_.unsqueeze(-3)   # (... x T_k x attn_dim) -> (... x  1  x T_k x attn_dim)\n",
    "\n",
    "        # Sum thanks to Broadcasting Semantics\n",
    "        attn_hid = torch.tanh(q_ + k_ + self.bias) # (... x T_q x  1  x attn_dim) + (... x  1  x T_k x attn_dim) + (attn_dim) -> (... x T_q x T_k x attn_dim)\n",
    "\n",
    "        attn_logits = self.w(attn_hid)        # (... x T_q x T_k x attn_dim) -> (... x T_q x T_k x 1)\n",
    "        attn_logits = attn_logits.squeeze(-1) # (... x T_q x T_k x 1) -> (... x T_q x T_k)\n",
    "\n",
    "        attn_weights = F.softmax(attn_logits, dim=-1)\n",
    "\n",
    "        # TODO: Compute the output of the attention\n",
    "        output = torch.matmul(attn_weights, value)\n",
    "\n",
    "        return output, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGsTFfL7yvUb"
   },
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 721,
     "status": "ok",
     "timestamp": 1759037828257,
     "user": {
      "displayName": "QUỲNH VÕ THỊ NHƯ",
      "userId": "17221286096005268268"
     },
     "user_tz": -420
    },
    "id": "mRzLycxKHciC",
    "outputId": "24e04f26-6e98-4b87-cc64-494e9efec6d0"
   },
   "outputs": [],
   "source": [
    "!wget http://www.manythings.org/anki/cat-eng.zip\n",
    "!unzip cat-eng.zip && rm cat-eng.zip\n",
    "!mkdir data\n",
    "!mv \"cat.txt\" \"data/eng-cat.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f9KTbHaCHciD"
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iBxJSbT9y9jo"
   },
   "source": [
    "## Data pre-processing\n",
    "\n",
    "First we need to pre-process the raw text data. We need to make sure to lowercase all of it, remove all non-letter characters, and limit the maximum lenght of the sentences to MAX_LENGTH. Eventually, we create ```pairs```, a list where each component has a sentence and its translation, both pre-processed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 205,
     "status": "ok",
     "timestamp": 1759037832306,
     "user": {
      "displayName": "QUỲNH VÕ THỊ NHƯ",
      "userId": "17221286096005268268"
     },
     "user_tz": -420
    },
    "id": "iZ9eStIxHciD",
    "outputId": "4a26363c-6bea-4103-ab70-0c72e7a5bd7b"
   },
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Remove extra info\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        new_lines.append(line[0:(line.find('CC-BY')-1)])\n",
    "\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in new_lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'cat', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V29yklurzHIo"
   },
   "source": [
    "We have a total of 1306 pairs of sentences containing 1436 english words and 1773 catalan words. We use a very small dataset to reduce training time, but a larger dataset would be necessary to learn something meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZedNSCNzQ2g"
   },
   "source": [
    "## Building the seq2seq model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vxLIx4S0mUA_"
   },
   "source": [
    "We proceed to build our seq2seq model with attention. First we define our encoder RNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cM_GojMEC-fF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a1eDA6aFHciF"
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # TODO: Define the Embedding matrix (use nn.Embedding)\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxm-SsMxZfCz"
   },
   "source": [
    "Now we define our decoder, with an attention mechanism (```self.attn```) built inside. Try to map the code with the following diagram:\n",
    "\n",
    "<p align=\"center\"><br>\n",
    "<img src=\"https://github.com/telecombcn-dl/labs-all/raw/main/labs/attention/images/attention_tensor_dance_last.jpeg?raw=true\" class=\"center\" title=\"Decoding with attention\" width=\"800\"/>\n",
    "</p><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUcH-nIaHciH"
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size, batch_first=True)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        # Here we define the attention we use\n",
    "        self.attn = AdditiveAttention(self.hidden_size, self.hidden_size, self.hidden_size // 2)\n",
    "        #self.attn = MultiplicativeAttention(self.hidden_size, self.hidden_size)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        x, hidden = self.gru(embedded, hidden)\n",
    "        context, attn_weights = self.attn(query=x, key=encoder_outputs, value=encoder_outputs)\n",
    "\n",
    "        # TODO: compute concatenation of the decoder hidden states and the context vectors\n",
    "        x_w_context = torch.cat((x, context), dim=-1)\n",
    "\n",
    "        x_w_context = self.attn_combine(x_w_context)\n",
    "        output = F.log_softmax(self.out(x_w_context), dim=-1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_oA4zvAnHciI"
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTEsKlF1HciI"
   },
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "    # First hidden state used by the decoder is the last encoder hidden state\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # We feed the decoder with the whole target sentence (teacher forcing),\n",
    "    # first we append SOS_token\n",
    "    decoder_input = torch.cat([\n",
    "        torch.tensor([[SOS_token]], device=device),\n",
    "        target_tensor[:, :-1]\n",
    "    ], dim=1)\n",
    "\n",
    "\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "    loss = criterion(\n",
    "        decoder_output.view(-1, decoder_output.size(-1)),\n",
    "        target_tensor.view(-1)\n",
    "    )\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_tensor.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3SRW_D3HciI"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CktDoKfbHciI"
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Random sample of n_iters pairs\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 740
    },
    "executionInfo": {
     "elapsed": 220391,
     "status": "ok",
     "timestamp": 1759038110628,
     "user": {
      "displayName": "QUỲNH VÕ THỊ NHƯ",
      "userId": "17221286096005268268"
     },
     "user_tz": -420
    },
    "id": "bEaJggtCHciJ",
    "outputId": "7b7f8f2e-0250-4d81-ec05-22b5319433e6"
   },
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 50000, print_every=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnqXv0C3HciJ"
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = []\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            decoder_attentions.append(decoder_attention.squeeze(0).data)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.squeeze().item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(output_lang.index2word[topi.squeeze().item()])\n",
    "            decoder_input = topi.detach().squeeze(1)\n",
    "\n",
    "        return decoded_words, torch.cat(decoder_attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBM4VsKiORp3"
   },
   "outputs": [],
   "source": [
    "def sentence_accuracy(pred_tokens, ref_tokens):\n",
    "    # cắt theo độ dài nhỏ hơn\n",
    "    min_len = min(len(pred_tokens), len(ref_tokens))\n",
    "    correct = sum(1 for i in range(min_len) if pred_tokens[i] == ref_tokens[i])\n",
    "    return correct / max(len(ref_tokens), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r85CE2r-HciJ"
   },
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('Source:', pair[0])\n",
    "        print('Reference:', pair[1])\n",
    "\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words[:-1])\n",
    "\n",
    "        print('Model:', output_sentence)\n",
    "\n",
    "        # tokenized reference and hypothesis\n",
    "        ref_tokens = pair[1].split()\n",
    "        hyp_tokens = output_sentence.split()\n",
    "\n",
    "        # Accuracy\n",
    "        acc = sentence_accuracy(hyp_tokens, ref_tokens)\n",
    "        # BLEU (nghiêng về n-gram, nên dùng smoothing cho câu ngắn)\n",
    "        bleu = sentence_bleu([ref_tokens], hyp_tokens, smoothing_function=smoothie)\n",
    "\n",
    "        print(f'Accuracy: {acc:.2f}, BLEU: {bleu:.2f}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1759038112098,
     "user": {
      "displayName": "QUỲNH VÕ THỊ NHƯ",
      "userId": "17221286096005268268"
     },
     "user_tz": -420
    },
    "id": "ARbjLn6EHciK",
    "outputId": "dc5b7938-c626-4600-fb67-bdea9b84cec1"
   },
   "outputs": [],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 842,
     "status": "ok",
     "timestamp": 1759039196522,
     "user": {
      "displayName": "QUỲNH VÕ THỊ NHƯ",
      "userId": "17221286096005268268"
     },
     "user_tz": -420
    },
    "id": "Zyw_jLzHHciK",
    "outputId": "4273fe6c-49ae-4d2a-b1fe-b60e3dd9f59f"
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    import pandas as pd\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    #cax = ax.matshow(attentions.numpy(), cmap='Blues')\n",
    "    #fig.colorbar(cax)\n",
    "    sns.set(rc={'figure.figsize':(12, 8)})\n",
    "    input_sentence_list = input_sentence.split(' ') + ['<EOS>']\n",
    "\n",
    "    df = pd.DataFrame(attentions, columns = input_sentence_list, index = output_words)\n",
    "    ax = sns.heatmap(\n",
    "        df.astype(float),\n",
    "        linewidth=0.5,\n",
    "        cmap=\"Blues\",\n",
    "        square=True)\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions.detach().cpu())\n",
    "\n",
    "\n",
    "evaluateAndShowAttention(\"your son is a genius .\")\n",
    "\n",
    "evaluateAndShowAttention(\"i can t remember which is my racket .\")\n",
    "\n",
    "evaluateAndShowAttention(\"please circle the right answer .\")\n",
    "\n",
    "evaluateAndShowAttention(\"i d like to reserve a table for two .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hUKNPg_HciK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
